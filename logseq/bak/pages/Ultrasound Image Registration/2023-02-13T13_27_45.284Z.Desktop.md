- [[@Real-Time Image Fusion Involving Diagnostic Ultrasound]]
- US-US Image Fusion
	- Input data: 1st US image
	  Output data: Subsequent US frames
	  US-US image registration methods: Convolutional Neural Network (CNN) based rigid registration and transform matrix alignment
	  Measurement method: TRE (target registration error) is the distance between the target landmark and registered landmark. Ideally it should be 0.
	  World coordinate: focus point of US (Pointbase Reg)
	  Ground truth: first frame of US images
	  Image registration: all the US frames will be registered to the first frame (ground truth)
	  Landmark (L1):  reference point (the first automatically selected point for delineating the points of interest for tracking.
	  Point-of-interest (red dot): manually choose the point for the treatment region (will be verified by clinicians (may remove and add more points).
- US-CT Image Fusion
	- Input: CT (reference) and US images (moving images)
	  Output: Transformed CT images
	  Strategy: full sequence learning
	  Method:
		- Calculate the distance between outline/contour of CT plane and US
		- Align the US to CT (fixed image) in accordance with the distance map through haudsoff and mean surface distances
		- Register the US images in 3D space
- US-MRI Image Fusion
  id:: 63268c0b-88ab-4977-837f-bdc1d6ccc827
	- [Feishu Doc](https://ultrastmedtech.feishu.cn/wiki/wikcnoMfR2elHxTbn8YXn038Zgb)
	- LLC 
	  https://www.sciencedirect.com/science/article/abs/pii/S1361841514000620
	- BOBYQA
	- Surrogate
	- NOMAD
	- Pysot